# Urban Operations — Python

A small utility project that demonstrates a simple pipeline for collecting urban data (traffic, weather, pollution), transforming it, running a light ML training pipeline, and serving predictions via a FastAPI model server. This README was generated by analyzing the repository source files and explains how to run and develop the project locally.

## Repository layout

- `app/` — main package containing application code
	- `ai/` — model training and model server (`model_train.py`, `model_server.py`)
	- `etl/` — data fetchers and ETL helpers (`fetch_traffic_data.py`, `fetch_weather_data.py`, `fetch_pollution_data.py`, `transform_data.py`, `load_to_db.py`)
	- `api/` — outbound API helper to send results (`send_to_backend.py`)
	- `automation/` — scheduler wrapper that runs ETL + prediction cycles (`scheduler.py`)
	- `config/` — settings and logging configuration (`settings.py`, `logging_config.py`)
	- `utils/` — small helpers (`api_helper.py`, `data_cleaner.py`)
	- `models/` — serialized model artifacts (e.g. `traffic_model.joblib`)
	- `tests/` — unit tests (pytest)

Top-level files: `Dockerfile`, `docker-compose.yml`, `requirements.txt`, and a (previously empty) `README.md` that this file replaces.

## Quick prerequisites

- Python 3.9+ (3.10/3.11 recommended)
- pip
- (optional) Docker & docker-compose for containerized runs
- network access for the example external weather/pollution APIs

Create and activate a virtual environment (Windows/cmd example):

```cmd
python -m venv venv
venv\Scripts\activate
pip install --upgrade pip
pip install -r requirements.txt
```

Notes about running: many modules use package-relative imports (e.g. `from ..config.settings import ...`). To ensure these imports work, run scripts as modules from the project root using `python -m <module>` or run via `uvicorn` with the Python module path.

## Configuration / Environment

Configuration lives in `app/config/settings.py`. Several environment variables are read via `python-dotenv`:

- `AI_MODEL_PATH` — path to persisted model (default `./app/models/traffic_model.joblib`)
- `AI_API_URL` — prediction endpoint URL used by the scheduler (default `http://127.0.0.1:9000/predict`)
- `BACKEND_API_URL` — where predictions are posted (default `http://localhost:8080/api/traffic/predictions`)
- `DB_URL` — database connect string (default `mysql+pymysql://root:password@localhost:3306/smartcity`)
- `LOG_DIR` — path for logs (default `./logs`)

Create a `.env` file at the repository root (optional) with custom values, for example:

```text
AI_MODEL_PATH=./app/models/traffic_model.joblib
AI_API_URL=http://127.0.0.1:9000/predict
BACKEND_API_URL=http://localhost:8080/api/traffic/predictions
DB_URL=mysql+pymysql://root:password@localhost:3306/smartcity
LOG_DIR=./logs
```

Important: there is an inconsistency in the codebase: `app/config/settings.py` defines `DB_URL`, but `app/etl/load_to_db.py` expects `DB_URI`. If you plan to use the DB loader, either set `DB_URI` in your environment or edit `load_to_db.py` to use `DB_URL`.

## Running the model server (FastAPI)

The model server is implemented in `app/ai/model_server.py` and exposes:

- `POST /predict` — accepts JSON with `latitude`, `longitude`, `hour` and returns `predicted_speed`.
- `GET /weather` — returns a small weather DataFrame fetched from the weather fetcher.
- `GET /pollution` — returns a small pollution DataFrame fetched from the pollution fetcher.

Start the server using `uvicorn` from the project root so package-relative imports work:

```cmd
pip install uvicorn
uvicorn app.ai.model_server:app --host 0.0.0.0 --port 9000 --reload
```

If the model file at `AI_MODEL_PATH` is present and loadable, the server will use it. Otherwise the server uses a fallback prediction value and logs a warning.

## Training the model

Model training is available in `app/ai/model_train.py`. It generates synthetic traffic data and trains a RandomForestRegressor, then writes the artifact to `AI_MODEL_PATH`.

Run training as a module to ensure relative imports succeed:

```cmd
python -m app.ai.model_train
```

After training, the `traffic_model.joblib` is written to the path defined by `AI_MODEL_PATH` and can be loaded by the model server.

## ETL: fetching, transforming and loading

ETL helpers are in `app/etl/`:

- `fetch_traffic_data.py` — simulates recent traffic readings and returns a pandas DataFrame.
- `fetch_weather_data.py` — fetches hourly temperature from Open-Meteo and returns a DataFrame (uses `requests`).
- `fetch_pollution_data.py` — generates simulated pollutant readings.
- `transform_data.py` — (present) transform helpers for ETL (inspect file for details).
- `load_to_db.py` — attempts to write a DataFrame to MySQL using SQLAlchemy. Note: this file imports `DB_URI` while `settings.py` defines `DB_URL`. Update either the env var or the file before using.

Run ETL functions from Python or via a small driver script. Because several ETL modules use package-relative imports, prefer:

```cmd
python -m app.etl.fetch_weather_data
python -m app.etl.fetch_traffic_data
python -m app.etl.fetch_pollution_data
```

Note: some files include `if __name__ == "_main_":` (typo) instead of `if __name__ == "__main__":`. Those `__main__` guards will not execute as-is. To run them, call via `-m` or fix the guard in the source.

## Scheduler / automation

`app/automation/scheduler.py` demonstrates a simple scheduled workflow:

- Fetches a small batch of traffic rows (`fetch_traffic_data`) — default `n=5`.
- For each row, posts a request to the model server (default `http://127.0.0.1:9000/predict`).

Run this : uvicorn app.ai.model_server:app --reload --port 9000 

- Appends predictions to the DataFrame and calls `send_results_to_backend` to POST results to `BACKEND_API_URL`.

Run the scheduler (it uses `schedule` and will run continuously):

```cmd
python -m app.automation.scheduler
```

Or run it in Docker (if you containerize services). Note: the scheduler performs an immediate first run and then sleeps waiting for scheduled intervals.

## Sending results to backend

`app/api/send_to_backend.py` posts prediction results to the backend configured by `BACKEND_API_URL`. By default it points to `http://localhost:8080/api/traffic/predictions` — ensure a receiving endpoint is available or change the URL.

## Utilities

- `app/utils/api_helper.py` — small `get_json_with_retries` helper (note: the implementation returns `None` early on failure; review if you want retries to loop instead of returning on first exception).
- `app/utils/data_cleaner.py` — basic cleaning helpers (parsing datetimes, converting numeric columns).

## Testing

Tests are present in `app/tests/` but appear empty in this repository snapshot. To run tests when available:

```cmd
pytest -q
```

Add unit tests for ETL functions and the model server client to make CI reliable.

## Docker

The repository includes `Dockerfile` and `docker-compose.yml` for containerized runs. Typical steps (from repo root):

```cmd
docker-compose build
docker-compose up
```

Adjust `docker-compose.yml` service URLs so the scheduler and API can reach the model server by service name.

## Known issues & recommended quick fixes (observed during analysis)

1. `load_to_db.py` imports `DB_URI` but `settings.py` defines `DB_URL`.
	 - Quick fix: edit `app/etl/load_to_db.py` to import `DB_URL` or set `DB_URI` in your environment. Example change:

```py
from ..config.settings import DB_URL as DB_URI
```

2. Some modules use incorrect `__main__` guard (e.g. `if __name__ == "_main_":`). These will not execute when run as scripts. Replace with `if __name__ == "__main__":` if you want them runnable directly.

3. `app/utils/api_helper.py` currently logs retries but returns `None` after the first exception; you may want to move the `return None` outside the retry loop so it actually retries.

4. Ensure you run modules as packages when code uses relative imports. Use `python -m app.ai.model_train` or `uvicorn app.ai.model_server:app`.

## Contributing & next steps

- Add a `LICENSE` (e.g., MIT) if you want the repo to be open-source.
- Add `.env.example` listing required environment variables.
- Fix the small bugs listed in "Known issues" and add unit tests that cover ETL and model training.
- Optionally add a small CLI in `app/main.py` to run common tasks like `train`, `serve`, `etl`, and `scheduler`.

If you want, I can:

- commit a small patch that fixes the `DB_URI`/`DB_URL` mismatch and the `__main__` guards,
- add a `.env.example` and `LICENSE` file,
- add a tiny `app/main.py` CLI to run tasks more ergonomically.

Tell me which of these actions you'd like me to take next and I'll implement them.

